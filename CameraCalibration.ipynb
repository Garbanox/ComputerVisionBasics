{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "absolute-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-magnet",
   "metadata": {},
   "source": [
    "# Camera Calibration and Undistorting Images\n",
    "In this notebook we are going to calibrate a monocular camera (i.e. estimate the camera matrix and distortion parameters) and use the calibration to undistort an image. We will start by using the standard OpenCV functions first and later implement the calibration and undistortion form scratch using numpy and scipy.\n",
    "## Camera Calibration using OpenCV\n",
    "I have printed out a [chessboard pattern](https://github.com/opencv/opencv/blob/master/doc/pattern.png) and took pictures of it using my phone's camera. For efficiency reasons I scaled down the images by a factor of 2. We will follow the [official OpenCV tutorial on camera calibration](https://docs.opencv.org/master/dc/dbb/tutorial_py_calibration.html).\n",
    "<img src=\"data/IMG_1239.jpg\" alt=\"drawing\" width=\"30%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prescription-single",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 29 images and found 29 chessboards.\n"
     ]
    }
   ],
   "source": [
    "# Extract circle centers for all images. This might take a while...\n",
    "image_files = glob.glob('data/*.jpg')\n",
    "\n",
    "grid_size = 25 # mm\n",
    "grid_shape = (9,6)\n",
    "\n",
    "image_corners = np.zeros((0, grid_shape[0]*grid_shape[1] ,2))\n",
    "chessboard_positions = np.zeros((grid_shape[0]*grid_shape[1],3))\n",
    "chessboard_positions[:,:2] = np.mgrid[0:grid_shape[0],0:grid_shape[1]].T.reshape(-1,2)\n",
    "chessboard_positions *= grid_size\n",
    "image_shape = np.array([])\n",
    "\n",
    "for file in image_files:\n",
    "    img = cv2.cvtColor(cv2.imread(file), cv2.COLOR_BGR2GRAY)\n",
    "    image_shape = img.shape\n",
    "    ret, corners = cv2.findChessboardCorners(img, grid_shape)\n",
    "    if ret:\n",
    "        image_corners = np.append(image_corners, np.array(corners).reshape(1, -1, 2), axis=0)\n",
    "    else:\n",
    "        print(f\"No chessboard detected in image {file}\")\n",
    "print(f\"Processed {len(image_files)} images and found {image_corners.shape[0]} chessboards.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alpine-pacific",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera matrix returned by OpenCV:\n",
      "[[1534.97    0.   1010.01]\n",
      " [   0.   1558.1   747.42]\n",
      " [   0.      0.      1.  ]]\n",
      "Distortion coefficients returned by OpenCV:\n",
      "k1: +2.213e-01; \tk2: -9.994e-01; \tp1: -2.081e-05; \tp2: +4.839e-05\n"
     ]
    }
   ],
   "source": [
    "def calibrate_camera_openCV():\n",
    "    object_points = np.tile(chessboard_positions, (image_corners.shape[0], 1, 1))\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(object_points.astype(np.float32), image_corners.astype(np.float32), image_shape[::-1], None, None)\n",
    "    return mtx, dist[0]\n",
    "\n",
    "camera_mat_cv, dist_cv = calibrate_camera_openCV()\n",
    "print(\"Camera matrix returned by OpenCV:\")\n",
    "with np.printoptions(suppress=True, precision=2):\n",
    "    print(camera_mat_cv)\n",
    "print(\"Distortion coefficients returned by OpenCV:\")\n",
    "print(f\"k1: {dist_cv[0]:+.3e}; \\tk2: {dist_cv[1]:+.3e}; \\tp1: {dist_cv[2]:+.3e}; \\tp2: {dist_cv[3]:+.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-offset",
   "metadata": {},
   "source": [
    "## Camera Calibration from Scratch\n",
    "### Estimating the Camera Matrix\n",
    "In this section we are going to implement the camera calibration procedure inspired by [Zhang '98](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr98-71.pdf). \n",
    "We write down the perspective projection equation for a planar grid. The origin of the world is therefore defined by the chessboardd pattern. Note that all z-coordinates are zero because all world points lie on the plane. \n",
    "\n",
    "$$ \n",
    "\\lambda \\left( \\begin{array}{r} u \\\\ v \\\\ 1 \\end{array}\\right) = K \n",
    "\\left[ \\begin{array}{c c} R_{cw} &  T_{cw} \\end{array}\\right] \n",
    "\\left( \\begin{array}{c} X_w \\\\ Y_w \\\\ 0 \\\\ 1\\end{array}\\right) = \n",
    "\\underbrace{K \\left[ \\begin{array}{c c } r_1 & r_2 & t\\end{array}\\right]}_{H} \n",
    "\\left( \\begin{array}{c} X_w \\\\ Y_w \\\\ 1\\end{array}\\right)\n",
    "$$\n",
    "The matrix $H$ is the same for all corners in one image and can be estimated using for example the **direct linear transform (DLT)**. This however assumes that all elements in $H$ are independent which in in general not the case. We will only use the DLT only as a first guess and refine the estimation later on using all constraints.\n",
    "\n",
    "$$ \n",
    "\\lambda \\left( \\begin{array}{r} u \\\\ v \\\\ 1 \\end{array}\\right) = \n",
    "\\left( \\begin{array}{ccc}\n",
    "    h_{11} & h_{12} & h_{13}\\\\ h_{21} & h_{22} & h_{23} \\\\ h_{31} & h_{32} & h_{33}\n",
    "\\end{array}\\right) \n",
    "\\left( \\begin{array}{c} X_w \\\\ Y_w \\\\ 1\\end{array}\\right) = \n",
    "\\left( \\begin{array}{c}h_1^T \\\\ h_2^T \\\\ h_3^T\\end{array}\\right) P \n",
    "\\Rightarrow \n",
    "\\left\\{\n",
    "\\begin{array}{l l}\n",
    "    u = \\frac{\\lambda u}{\\lambda} = \\frac{h_1^T \\cdot P}{h_3^T \\cdot P} \\\\ \n",
    "    v = \\frac{\\lambda v}{\\lambda} = \\frac{h_2^T \\cdot P}{h_3^T \\cdot P}\n",
    "\\end{array}\\right.\n",
    "\\Rightarrow \n",
    "\\left\\{\n",
    "\\begin{array}{l l}\n",
    "    (h_1^T - u h_3^T)\\cdot P=0 \\\\ \n",
    "    (h_2^T - v h_3^T)\\cdot P=0 \n",
    "\\end{array}\\right.\n",
    "\\Rightarrow \n",
    "\\left( \\begin{array}{ccc}\n",
    "P^T & 0^T & -uP^T \\\\0^T & P^T & -vP^T\n",
    "\\end{array}\\right) \n",
    "\\left( \\begin{array}{c}h_1 \\\\ h_2 \\\\ h_3\\end{array}\\right) =0 $$\n",
    "\n",
    "This reasoning can be applied to all n corners in one image and the resulting equations can be stacked to yield one big matrix. The matrix $Q$ can be constructed using the observed corners. The least square solution for $H$ can be found with the **Singular Value Decomposition (SVD)** ([Wikipedia](https://en.wikipedia.org/wiki/Singular_value_decomposition#Solving_homogeneous_linear_equations)).\n",
    "$$ \\underbrace{\\left( \\begin{array}{ccc}\n",
    "P_1^T & 0^T & -u_1P_1^T \\\\\n",
    "0^T & P_1^T & -v_1P_1^T \\\\ \n",
    "P_2^T & 0^T & -u_2P_2^T \\\\\n",
    "0^T & P_2^T & -v_2P_2^T \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "P_n^T & 0^T & -u_nP_n^T \\\\\n",
    "0^T & P_n^T & -v_nP_n^T \\end{array} \\right)}_{Q\\in\\mathbb{R}^{2n \\times 9}} \\left( \\begin{array}{c}h_1 \\\\ h_2 \\\\ h_3\\end{array}\\right) = Q \\cdot H' = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brilliant-cinema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.11077081e-03 1.46102659e-04 2.71518127e-01]\n",
      " [3.97549542e-04 7.06366424e-03 9.62380051e-01]\n",
      " [3.58815984e-07 2.88318579e-07 1.38076544e-03]]\n",
      "Average perspective projection equation error: 1.0310488434658875 px\n"
     ]
    }
   ],
   "source": [
    "def calculate_H_DLT(corners, chessboard_positions):\n",
    "    n = corners.shape[0]\n",
    "    \n",
    "    P = chessboard_positions.copy();\n",
    "    P[:,2] = 1\n",
    "    \n",
    "    Q = np.zeros((2*n, 9))\n",
    "    Q[::2,0:3] = P\n",
    "    Q[1::2,3:6] = P\n",
    "    Q[::2,6:9] = -(P.T * corners[:,0]).T\n",
    "    Q[1::2,6:9] = -(P.T * corners[:,1]).T\n",
    "    \n",
    "    U, D, Vh = np.linalg.svd(Q, full_matrices=True)\n",
    "    # Row in vh that is associated with the smalles singular value gives solution\n",
    "    H_tilde = Vh[-1,:]\n",
    "    H = H_tilde.reshape(3,3)\n",
    "    return H\n",
    "    \n",
    "def test_H_DLT():\n",
    "    H_0 = calculate_H_DLT(image_corners[0], chessboard_positions)\n",
    "    print(H_0)  \n",
    "    \n",
    "    # Check that perspective projection equation is approximately fulfilled\n",
    "    P = chessboard_positions.copy();\n",
    "    P[:,2] = 1\n",
    "    \n",
    "    pixels_h = H_0 @ P.T;\n",
    "    pixels = pixels_h[0:2,:]/pixels_h[2,:]\n",
    "    \n",
    "    print(\"Average perspective projection equation error:\", \n",
    "          np.average(np.linalg.norm(pixels.T - image_corners[0], axis=1)), 'px')\n",
    "\n",
    "test_H_DLT()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-india",
   "metadata": {},
   "source": [
    "We can now compute the homography $H_i$ for each image $i$. Note that the scale of $H$ can be arbitrary chosen beause the homogeneous equation $Q\\cdot sH'=0$ is satisfied for any $s\\in\\mathbb{R}$. In the next step we need to extract the camera matrix from all matrices $H_i$. We will use the constraints imposed by the rotation matrix and rewrite the vectors $r_1$ and $r_2$ using $H$ and $K$ (and an unknown scale factor $s$). The vectors $g_j$ are the column vectors of $H$ and are not to be confused with the row vectors $h_j$ used in the derivation of $H$.\n",
    "$$ H = \\left[ \\begin{array}{c c c} g_1 & g_2 & g_3 \\end{array}\\right] = \n",
    "sK\\left[ \\begin{array}{c c c} r_1 & r_2 & t \\end{array}\\right] \\Rightarrow \\left\\{\n",
    "\\begin{array}{l l} r_1 = s^{-1} K^{-1}g_1 \\\\ r_2 = s^{-1} K^{-1}g_2 \\end{array}\\right.$$\n",
    "The constraints on the rotation matrix impose that $r_1$ and $r_2$ are orthonormal which translates to:\n",
    "$$ \n",
    "\\begin{align}\n",
    "    r_1 \\cdot r_2 = 0 & \\Rightarrow g_1^TK^{-T}K^{-1}g_2 = 0 \\\\\n",
    "    r_1 \\cdot r_1 = 1 = r_2 \\cdot r_2 & \\Rightarrow g_1^TK^{-T}K^{-1}g_1 = g_2^TK^{-T}K^{-1}g_2.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We define the symmetric matrix $B$ which is defined by the vector $b'= \\left( \\begin{array}{llllll}\n",
    "    b_{11} & b_{12} & b_{22} & b_{13}  & b_{23} & b_{33} \\end{array}\\right)^T$ as\n",
    "$$ B = \\left( \\begin{array}{ccc}\n",
    "    b_{11} & b_{12} & b_{13}\\\\ b_{12} & b_{22} & b_{23} \\\\ b_{13} & b_{23} & b_{33}\n",
    "\\end{array}\\right)  = K^{-T}K^{-1}.$$\n",
    "Using this noteation, the constraints can be rewritten as linear function of $b'$:\n",
    "$$ g_i^T B g_j = v_{ij}^Tb' $$\n",
    "with \n",
    "$$ v_{ij} = \\left( \\begin{array}{llllll} h_{1,i}h_{1,j} & h_{1,i}h_{2,j}+h_{2,i}h_{1,j} & h_{2,i}h_{2,j} & h_{3,i}h_{1,j}+h_{1,i}h_{3,j} & h_{3,i}h_{2,j}+h_{2,i}h_{3,j} & h_{3,i}h_{3,j}\\end{array}\\right)^T.$$\n",
    "The corresponding two homogeneous equation in $b'$ are:\n",
    "$$ \\left( \\begin{array}{c}\n",
    "v_{12}^T \\\\ (v_{11}-v_{22})^T\n",
    "\\end{array}\\right) b' = 0. $$\n",
    "For each image $i$ we obtain two homogeneous equations that we stack to the matrix $V$. $b'$ is found again with the SVD.\n",
    "$$ Vb'=0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nearby-tourism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.58805673e-07 -9.94081941e-10 -2.60286939e-04]\n",
      " [-9.94081941e-10  2.51578496e-07 -1.86041522e-04]\n",
      " [-2.60286939e-04 -1.86041522e-04  9.99999949e-01]]\n"
     ]
    }
   ],
   "source": [
    "def calculate_B_DLT(image_corners, chessboard_positions):\n",
    "    def v(i, j, H):\n",
    "        # Note the 0 indexing in numpy\n",
    "        return np.array([H[0,i]*H[0,j], \n",
    "                         H[0,i]*H[1,j] + H[1,i]*H[0,j], \n",
    "                         H[1,i]*H[1,j], \n",
    "                         H[2,i]*H[0,j] + H[0,i]*H[2,j], \n",
    "                         H[2,i]*H[1,j] + H[1,i]*H[2,j],\n",
    "                         H[2,i]*H[2,j]])\n",
    "    \n",
    "    n = image_corners.shape[0]\n",
    "    V = np.zeros((2*n, 6))\n",
    "    \n",
    "    for i in range(n):\n",
    "        H = calculate_H_DLT(image_corners[i], chessboard_positions)\n",
    "        V[2*i,:] = v(0, 1, H)\n",
    "        V[2*i+1,:] = v(0, 0, H) - v(1, 1, H)\n",
    "        \n",
    "    U, D, Vh = np.linalg.svd(V, full_matrices=True)\n",
    "    b = Vh[-1,:]\n",
    "    B = np.array([[b[0], b[1], b[3]],\n",
    "                  [b[1], b[2], b[4]],\n",
    "                  [b[3], b[4], b[5]]])\n",
    "    return B\n",
    "B = calculate_B_DLT(image_corners, chessboard_positions)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-foundation",
   "metadata": {},
   "source": [
    "We can finally recover the calibration matrix $K$ from $B$ using the **Cholesky Factorization**. Keep in mind that we can only estimate $B$ up to a constant scale factor $\\alpha$. Therefore $B=\\alpha K^{-T}K^{-1}.$ We can safely ignore the scale factor at first and later rescale the obtained matrix $K$ so that $K_{33} =1$. Recall that the Cholesky Factorization factorizes a square matrix $A$ in the product of a lower-triangular matrix $L$ and a upper-triangular matrix $L^T$: $A=LL^T$. We apply this to $B$:\n",
    "$$ B = LL^T = K'^{-T}K'^{-1} \\Rightarrow K'=L^{-T} $$\n",
    "The camera matrix $K$ can now be recovered as:\n",
    "$$ K = \\frac{1}{K'_{33}}K' $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "apparent-sacramento",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our initial guess for the camera matrix\n",
      "[[1521.55    5.93 1008.58]\n",
      " [   0.   1543.26  743.48]\n",
      " [   0.      0.      1.  ]]\n",
      "Camera matrix obtained by OpenCV\n",
      "[[1534.97    0.   1010.01]\n",
      " [   0.   1558.1   747.42]\n",
      " [   0.      0.      1.  ]]\n"
     ]
    }
   ],
   "source": [
    "def B_to_K(B):\n",
    "    L = np.linalg.cholesky(B)\n",
    "    K_p = np.linalg.inv(L).T\n",
    "    K = K_p/K_p[2,2]\n",
    "    \n",
    "    # Due to numeric imprecisions elements below the diaglonal are note exactely 0. We set then to 0 to be consistent.\n",
    "    K[1,0] = K[2,0] = K[2,1] = 0\n",
    "    return K\n",
    "\n",
    "camera_mat = B_to_K(B)\n",
    "with np.printoptions(suppress=True, precision=2):\n",
    "    print(\"Our initial guess for the camera matrix\")\n",
    "    print(camera_mat)\n",
    "    print(\"Camera matrix obtained by OpenCV\")\n",
    "    print(camera_mat_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-hearts",
   "metadata": {},
   "source": [
    "As we can see we are already pretty close to the OpenCV solution which is a good sign! :) We now need to estimate the distortion coefficients and refine our estimate with non-linear optimization.\n",
    "### Distortion Coefficients\n",
    "One could try to estimate the distortion coefficients by using a least squares approach as described in Zhang's paper to obtain an initial guess. This guess can then be refined with non-linear optimization. In practice however one can often skip this step and initialize the refinement with all distortion coefficients set to 0.\n",
    "#### Reprojection Error\n",
    "The reprojection error measures the euclidian distance in pixels between the observed corner position and the position obtained by projecting the point using $K$ and the distortion coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tracked-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reprojection_error(corners, chessboard_positions):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
